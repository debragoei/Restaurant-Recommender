{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220d1bc4-23ef-4764-ae52-c1fa88c029aa",
   "metadata": {},
   "source": [
    "# Topic Modelling in Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887283a-2394-4dad-9cf5-9c8871005ee2",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51720f16-255e-41d0-b041-7179b9a5700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f5e9ac-eef7-44db-9200-2faad28c2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cleaned data\n",
    "data = pd.read_csv('../Data/GTA_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5705a84-f470-4d70-9501-b04fc30443e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pretty', 'solid', 'vegan', 'spot', 'had', 'rice', 'bowl', 'there', 'today', 'that', 'came', 'with', 'bunch', 'of', 'stuff', 'all', 'the', 'ingredients', 'seemed', 'fresh', 'and', 'came', 'together', 'well', 'simple', 'and', 'tasty']]\n"
     ]
    }
   ],
   "source": [
    "# Converting words in reviews to a list\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)  \n",
    "\n",
    "# Convert to list\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b510080-4342-4f06-b17e-90e2a45cca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "        \n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6f734c0-2b93-4a21-8166-23d3eb9fc002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb175c6b-2d03-429a-9b0e-ef7aa40b72d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033aa15-1274-41d5-bcf5-74c69872b40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e11ad-a8b2-444a-9f9e-6b4bd376a1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa0faa33-271d-46c6-90de-21621d1a7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "grid_params = {'n_components' : list(range(5,10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a64c9-0f64-4f34-b158-1b44cada5a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da2bdfdd-fb0d-4596-b860-a93acaaf3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5,\n",
    "                                           random_state=42,\n",
    "                                           chunksize=250,\n",
    "                                           passes=5,\n",
    "                                           alpha='auto',\n",
    "                                           iterations=10,\n",
    "                                           per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad0da5fa-93c1-4770-afec-9bcacd81c10b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3p/bdw7d11x76q9r29tng0s109c0000gn/T/ipykernel_57529/278521920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Estimators for LDA model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "X = data['text']\n",
    "lda = LatentDirichletAllocation()\n",
    "lda_model = GridSearchCV(lda,param_grid=grid_params)\n",
    "lda_model.fit(X)\n",
    "# Estimators for LDA model\n",
    "lda_model1 = lda_model.best_estimator_\n",
    "print(\"Best LDA model's params\" , lda_model.best_params_)\n",
    "print(\"Best log likelihood Score for the LDA model\",lda_model.best_score_)\n",
    "print(\"LDA model Perplexity on train data\", lda_model1.perplexity(document_term_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d29a52-47df-47fb-85a6-7d5054be3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Viz\n",
    "\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(best_lda_model, small_document_term_matrix,small_count_vectorizer,mds='tsne')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
